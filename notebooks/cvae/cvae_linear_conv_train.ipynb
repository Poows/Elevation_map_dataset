{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMkUcvBjherm"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox, TextArea\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils import data\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import save_image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Training on',DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hVejExPohkzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "UZoAP_johm9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "learning_rate = 0.005\n",
        "image_shape = 100\n",
        "input_size = image_shape * image_shape\n",
        "hidden_size = 1000\n",
        "epoch = 600\n",
        "labels_length = 2"
      ],
      "metadata": {
        "id": "_tAJU8S_hoNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Grayscale(num_output_channels=1)\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "2gPhIQjohqBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/VKR/dataset_1200_100\"\n",
        "dataset = ImageFolder(root=dataset_path, transform=transform)"
      ],
      "metadata": {
        "id": "fUCgSf38hqZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])"
      ],
      "metadata": {
        "id": "Tyj-Bwyahsi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_dataset = DataLoader(test_data, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "3jwkVqk5htk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper functions\n",
        "def one_hot(x, max_x):\n",
        "    return torch.eye(max_x + 1)[x]\n",
        "\n",
        "def plot_gallery(images, h, w, n_row=3, n_col=6):\n",
        "    plt.figure(figsize=(2 * n_col, 2 * n_row))\n",
        "    for i in range(n_row * n_col):\n",
        "        plt.subplot(n_row, n_col, i + 1)\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(images[i].reshape(h, w), cmap = matplotlib.cm.binary)\n",
        "    plt.show()\n",
        "    \n",
        "def plot_loss(history):\n",
        "    loss, val_loss = zip(*history)\n",
        "    plt.figure(figsize=(15, 9))\n",
        "    plt.plot(loss, label=\"train_loss\")\n",
        "    plt.plot(val_loss, label=\"val_loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TT1LK1sOhvCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CVAE(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=1000):\n",
        "        super(CVAE, self).__init__()\n",
        "        input_size_with_label = input_size + labels_length\n",
        "        hidden_size += labels_length\n",
        "        \n",
        "        self.fc1 = nn.Linear(input_size_with_label,2048)\n",
        "        self.fc2 = nn.Linear(2048,1024)\n",
        "        self.fc23 = nn.Linear(1024,512)\n",
        "        self.fc21 = nn.Linear(512, hidden_size)\n",
        "        self.fc22 = nn.Linear(512, hidden_size)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        self.fc3 = nn.Linear(hidden_size, 512)\n",
        "        self.fc31 = nn.Linear(512, 1024)\n",
        "        self.fc32 = nn.Linear(1024, 2048)\n",
        "        self.fc4 = nn.Linear(2048, input_size)\n",
        "    \n",
        "    def encode(self, x, labels):\n",
        "        x = x.view(-1, 1*image_shape*image_shape)\n",
        "        x = torch.cat((x, labels), 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc23(x))\n",
        "        return self.fc21(x), self.fc22(x)\n",
        "        \n",
        "    def decode(self, z, labels):\n",
        "        torch.cat((z, labels), 1)\n",
        "        z = self.relu(self.fc3(z))\n",
        "        z = self.relu(self.fc31(z))\n",
        "        z = self.relu(self.fc32(z))\n",
        "        return torch.sigmoid(self.fc4(z))\n",
        "        \n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 *logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu)\n",
        "        \n",
        "    def forward(self,x, labels):\n",
        "        #targets = one_hot(targets,labels_length-1).float().to(DEVICE)\n",
        "        mu, logvar = self.encode(x, labels)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x = self.decode(z, labels)\n",
        "        return x, mu, logvar\n",
        "\n",
        "def train_cvae(net, dataloader, test_dataloader, flatten=True, epochs=20):\n",
        "    validation_losses = []\n",
        "    optim = torch.optim.Adam(net.parameters())\n",
        "\n",
        "    log_template = \"\\nEpoch {ep:03d} val_loss {v_loss:0.4f}\"\n",
        "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:  \n",
        "        for i in range(epochs):\n",
        "            for batch, labels in dataloader:\n",
        "                batch = batch.to(DEVICE)\n",
        "                labels = one_hot(labels,2).to(DEVICE)\n",
        "\n",
        "                if flatten:\n",
        "                    batch = batch.view(batch.size(0), image_shape*image_shape)\n",
        "\n",
        "                optim.zero_grad()\n",
        "                x,mu,logvar = net(batch, labels)\n",
        "                loss = vae_loss_fn(batch, x[:, :image_shape*image_shape], mu, logvar) # 784\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "            evaluate(validation_losses, net, test_dataloader, flatten=True)\n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(ep=i+1, v_loss=validation_losses[i]))\n",
        "    plt.show()\n",
        "    return validation_losses"
      ],
      "metadata": {
        "id": "R4d9Wug1hwdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvae = CVAE(image_shape*image_shape, hidden_size).to(DEVICE)"
      ],
      "metadata": {
        "id": "O8cZm-mhh0fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_loss_fn(x, recon_x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "def evaluate(losses, autoencoder, dataloader, flatten=True):\n",
        "    model = lambda x, y: autoencoder(x, y)[0]    \n",
        "    loss_sum = []\n",
        "    inp, out = [],[]\n",
        "    loss_fn = nn.MSELoss()\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = one_hot(labels,1).to(DEVICE)\n",
        "\n",
        "        if flatten:\n",
        "            inputs = inputs.view(inputs.size(0), image_shape*image_shape)\n",
        "\n",
        "        outputs = model(inputs, labels)\n",
        "        loss = loss_fn(inputs, outputs)            \n",
        "        loss_sum.append(loss)\n",
        "        inp = inputs\n",
        "        out = outputs\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        plot_gallery([inp[0].detach().cpu(),out[0].detach().cpu()],image_shape,image_shape,1,2)    \n",
        "\n",
        "    losses.append((sum(loss_sum)/len(loss_sum)).item())"
      ],
      "metadata": {
        "id": "j5b2_BoEh1zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cvae(net, dataloader, test_dataloader, flatten=True, epochs=50):\n",
        "    validation_losses = []\n",
        "    optim = torch.optim.Adam(net.parameters())\n",
        "\n",
        "    log_template = \"\\nEpoch {ep:03d} val_loss {v_loss:0.4f}\"\n",
        "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:  \n",
        "        for i in range(epochs):\n",
        "            for batch, labels in dataloader:\n",
        "                batch = batch.to(DEVICE)\n",
        "                labels = one_hot(labels,labels_length-1).to(DEVICE)\n",
        "                \n",
        "                if flatten:\n",
        "                    batch = batch.view(batch.size(0), image_shape*image_shape)\n",
        "\n",
        "                optim.zero_grad()\n",
        "                x,mu,logvar = net(batch, labels)\n",
        "                loss = vae_loss_fn(batch, x[:, :image_shape*image_shape], mu, logvar)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "            evaluate(validation_losses, net, test_dataloader, flatten=True)\n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(ep=i+1, v_loss=validation_losses[i]))\n",
        "    plt.show()\n",
        "    return validation_losses"
      ],
      "metadata": {
        "id": "yQuAKvkVh9QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_cvae(cvae, train_dataset, val_dataset, epochs=epoch)"
      ],
      "metadata": {
        "id": "dcmDH3l4h-du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = history\n",
        "plt.figure(figsize=(15, 9))\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_oTwQGnjh_9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CVAE convolutional "
      ],
      "metadata": {
        "id": "GpZi1TpqkRBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    transform = torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               transforms.Grayscale(num_output_channels=1)])\n",
        "    dataset_path = \"D:/VKR/dataset/union_smaller_100\"\n",
        "    dataset = ImageFolder(root=dataset_path, transform=transform)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "    \n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "Go3lwhOzkZSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = load_data()"
      ],
      "metadata": {
        "id": "pMP---xwk47v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self,latent_size=32,num_classes=2, image_shape=100):\n",
        "        super(Model,self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "        self.num_classes = num_classes\n",
        "        self.original_image_shape = image_shape\n",
        "        self.image_shape = image_shape\n",
        "        self.kernal_size = 5\n",
        "        self.stride = 2\n",
        "\n",
        "        # For encode\n",
        "        sh = (self.kernal_size + (self.kernal_size - 1) * self.stride)\n",
        "        self.conv1 = nn.Conv2d(2, 16, kernel_size=5, stride=2) # image_shape - 13 + 1\n",
        "        self.sig = nn.Sigmoid()\n",
        "        self.image_shape = self.image_shape - sh + 1\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
        "        self.image_shape = self.image_shape - sh + 1\n",
        "        self.linear1 = nn.Linear(22*22*32,300) # 4*4*32\n",
        "        self.mu = nn.Linear(300, self.latent_size)\n",
        "        self.logvar = nn.Linear(300, self.latent_size)\n",
        "\n",
        "        # For decoder\n",
        "        self.linear2 = nn.Linear(self.latent_size + self.num_classes, 300)\n",
        "        self.linear3 = nn.Linear(300,10*10*32)\n",
        "        self.conv3 = nn.ConvTranspose2d(32, 16, kernel_size=5,stride=2) # H_out ​= (H_in​−1)*stride[0] − 2×padding[0] + dilation[0]×(kernel_size[0]−1) + output_padding[0] + 1\n",
        "                                                                        # W_out​ = (Win​−1)×stride[1] − 2×padding[1] + dilation[1]×(kernel_size[1]−1) + output_padding[1] + 1\n",
        "        self.conv4 = nn.ConvTranspose2d(16, 1, kernel_size=5, stride=2)\n",
        "        self.conv5 = nn.ConvTranspose2d(1, 1, kernel_size=4, stride=2)\n",
        "\n",
        "    def encoder(self,x,y):\n",
        "        y = torch.argmax(y, dim=1).reshape((y.shape[0],1,1,1))\n",
        "        y = torch.ones(x.shape).to(device)*y\n",
        "        t = torch.cat((x,y),dim=1)\n",
        "        #print(t.shape)\n",
        "        t = F.relu(self.conv1(t))\n",
        "        #print(t.shape)\n",
        "        t = F.relu(self.conv2(t))\n",
        "        #print(t.shape)\n",
        "        t = t.reshape((x.shape[0], -1))\n",
        "        #print(t.shape)\n",
        "        #print(\"linear: \", self.image_shape)\n",
        "        t = F.relu(self.linear1(t))\n",
        "        mu = self.mu(t)\n",
        "        logvar = self.logvar(t)\n",
        "        return mu, logvar\n",
        "    \n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std).to(device)\n",
        "        return eps*std + mu\n",
        "    \n",
        "    def unFlatten(self, x, channels, new_is):\n",
        "        return x.reshape((x.shape[0], channels, new_is, new_is))\n",
        "\n",
        "    def decoder(self, z):\n",
        "        #print(\"z: \", z.shape)\n",
        "        t = F.relu(self.linear2(z))\n",
        "        #print(\"t_linear1: \", t.shape)\n",
        "        t = F.relu(self.linear3(t))\n",
        "        #print(\"t_linear2: \", t.shape)\n",
        "        t = self.unFlatten(t, 32, 10)\n",
        "        #print(\"t_unflatten: \", t.shape)\n",
        "        t = F.relu(self.conv3(t))\n",
        "        #print(\"t_conv1: \", t.shape)\n",
        "        t = F.relu(self.conv4(t))\n",
        "       # print(\"t_conv2: \", t.shape)\n",
        "        t = F.relu(self.conv5(t))\n",
        "        #print(\"t_conv3: \", t.shape)\n",
        "        return self.sig(t)\n",
        "\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        mu, logvar = self.encoder(x,y)\n",
        "        z = self.reparameterize(mu,logvar)\n",
        "\n",
        "        # Class conditioning\n",
        "        z = torch.cat((z, y.float()), dim=1)\n",
        "        pred = self.decoder(z)\n",
        "        return pred, mu, logvar\n",
        "\n",
        "\n",
        "def plot(epoch, pred, y,name='test_'):\n",
        "    if not os.path.isdir('./images'):\n",
        "        os.mkdir('./images')\n",
        "    fig = plt.figure(figsize=(16,16))\n",
        "    for i in range(2):\n",
        "        ax = fig.add_subplot(1,2,i+1)\n",
        "        ax.imshow(pred[i,0],cmap='gray')\n",
        "        ax.axis('off')\n",
        "        ax.title.set_text(str(y[i]))\n",
        "    plt.savefig(\"./images/{}epoch_{}.jpg\".format(name, epoch))\n",
        "    # plt.figure(figsize=(10,10))\n",
        "    # plt.imsave(\"./images/pred_{}.jpg\".format(epoch), pred[0,0], cmap='gray')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def loss_function(x, pred, mu, logvar):\n",
        "    recon_loss = F.binary_cross_entropy(pred, x, reduction='sum') #F.binary_cross_entropy mse_loss\n",
        "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss, kld\n",
        "\n",
        "\n",
        "def train(epoch, model, train_loader, optim):\n",
        "    reconstruction_loss = 0\n",
        "    kld_loss = 0\n",
        "    total_loss = 0\n",
        "    for i,(x,y) in enumerate(train_loader):\n",
        "        try:\n",
        "            label = np.zeros((x.shape[0], num_classes))\n",
        "            label[np.arange(x.shape[0]), y] = 1\n",
        "            label = torch.tensor(label)\n",
        "\n",
        "            #print(label)\n",
        "            \n",
        "            optim.zero_grad()   \n",
        "            pred, mu, logvar = model(x.to(device),label.to(device))\n",
        "            \n",
        "            recon_loss, kld = loss_function(x.to(device),pred, mu, logvar)\n",
        "            loss = recon_loss + kld\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            \n",
        "            total_loss += loss.cpu().data.numpy()*x.shape[0]\n",
        "            reconstruction_loss += recon_loss.cpu().data.numpy()*x.shape[0]\n",
        "            kld_loss += kld.cpu().data.numpy()*x.shape[0]\n",
        "            if i == 0:\n",
        "                print(\"Gradients\")\n",
        "                for name,param in model.named_parameters():\n",
        "                    if \"bias\" in name:\n",
        "                        print(name,param.grad[0],end=\" \")\n",
        "                    else:\n",
        "                        print(name,param.grad[0,0],end=\" \")\n",
        "                    print()\n",
        "        except Exception as e:\n",
        "            traceback.print_exe()\n",
        "            torch.cuda.empty_cache()\n",
        "            continue\n",
        "    \n",
        "    reconstruction_loss /= len(train_loader.dataset)\n",
        "    kld_loss /= len(train_loader.dataset)\n",
        "    total_loss /= len(train_loader.dataset)\n",
        "    return total_loss, kld_loss,reconstruction_loss\n",
        "\n",
        "def test(epoch, model, test_loader):\n",
        "    reconstruction_loss = 0\n",
        "    kld_loss = 0\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i,(x,y) in enumerate(test_loader):\n",
        "            try:\n",
        "                label = np.zeros((x.shape[0], num_classes))\n",
        "                label[np.arange(x.shape[0]), y] = 1\n",
        "                label = torch.tensor(label)\n",
        "\n",
        "                pred, mu, logvar = model(x.to(device),label.to(device))\n",
        "                recon_loss, kld = loss_function(x.to(device),pred, mu, logvar)\n",
        "                loss = recon_loss + kld\n",
        "\n",
        "                total_loss += loss.cpu().data.numpy()*x.shape[0]\n",
        "                reconstruction_loss += recon_loss.cpu().data.numpy()*x.shape[0]\n",
        "                kld_loss += kld.cpu().data.numpy()*x.shape[0]\n",
        "                if i == 0:\n",
        "                    # print(\"gr:\", x[0,0,:5,:5])\n",
        "                    # print(\"pred:\", pred[0,0,:5,:5])\n",
        "                    plot(epoch, pred.cpu().data.numpy(), y.cpu().data.numpy())\n",
        "            except Exception as e:\n",
        "                traceback.print_exe()\n",
        "                torch.cuda.empty_cache()\n",
        "                continue\n",
        "    reconstruction_loss /= len(test_loader.dataset)\n",
        "    kld_loss /= len(test_loader.dataset)\n",
        "    total_loss /= len(test_loader.dataset)\n",
        "    return total_loss, kld_loss,reconstruction_loss        \n",
        "\n",
        "\n",
        "\n",
        "def generate_image(epoch,z, y, model):\n",
        "    with torch.no_grad():\n",
        "        label = np.zeros((y.shape[0], num_classes))\n",
        "        label[np.arange(z.shape[0]), y] = 1\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        pred = model.decoder(torch.cat((z.to(device),label.float().to(device)), dim=1))\n",
        "        plot(epoch, pred.cpu().data.numpy(), y.cpu().data.numpy(),name='Eval_')\n",
        "        print(\"data Plotted\")\n",
        "\n",
        "\n",
        "def save_model(model, epoch):\n",
        "    if not os.path.isdir(\"./checkpoints\"):\n",
        "        os.mkdir(\"./checkpoints\")\n",
        "    file_name = './checkpoints/model_{}.pt'.format(epoch)\n",
        "    torch.save(model.state_dict(), file_name)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"dataloader created\")\n",
        "    model = Model().to(device)\n",
        "    print(\"model created\")\n",
        "    \n",
        "    if load_epoch > 0:\n",
        "        model.load_state_dict(torch.load('./checkpoints/model_{}.pt'.format(load_epoch), map_location=torch.device('cpu')))\n",
        "        print(\"model {} loaded\".format(load_epoch))\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
        "\n",
        "\n",
        "    train_loss_list = []\n",
        "    test_loss_list = []\n",
        "    for i in tqdm(range(load_epoch+1, max_epoch)):\n",
        "        model.train()\n",
        "        train_total, train_kld, train_loss = train(i, model, train_loader, optimizer)\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            test_total, test_kld, test_loss = test(i, model, test_loader)\n",
        "            if generate:\n",
        "                z = torch.randn(2, 32).to(device)\n",
        "                y = torch.tensor([1,2]) - 1\n",
        "                generate_image(i,z, y, model)\n",
        "            \n",
        "        print(\"Epoch: {}/{} Train loss: {}, Train KLD: {}, Train Reconstruction Loss:{}\".format(i, max_epoch,train_total, train_kld, train_loss))\n",
        "        print(\"Epoch: {}/{} Test loss: {}, Test KLD: {}, Test Reconstruction Loss:{}\".format(i, max_epoch, test_loss, test_kld, test_loss))\n",
        "\n",
        "        save_model(model, i)\n",
        "        train_loss_list.append([train_total, train_kld, train_loss])\n",
        "        test_loss_list.append([test_total, test_kld, test_loss])\n",
        "        np.save(\"train_loss\", np.array(train_loss_list))\n",
        "        np.save(\"test_loss\", np.array(test_loss_list))"
      ],
      "metadata": {
        "id": "AUkPBFJSk7zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"D:/VKR/CVAE/src/models/cvae_conv_bce_200.pt\")"
      ],
      "metadata": {
        "id": "aCpmuuWglAjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  #test_total, test_kld, test_loss = test(i, model, test_loader)\n",
        "  if generate:\n",
        "    z = torch.randn(1, 32).to(device)\n",
        "    y = torch.tensor([1])\n",
        "    label = np.zeros((y.shape[0], num_classes))\n",
        "    label[np.arange(z.shape[0]), y] = 1\n",
        "    label = torch.tensor(label)\n",
        "\n",
        "    pred = model.decoder(torch.cat((z.to(device),label.float().to(device)), dim=1))\n",
        "    pred = np.transpose(pred.detach().cpu().numpy().reshape(pred.shape[0], pred.shape[2], pred.shape[3]), (1, 2, 0))\n",
        "    plt.imshow(pred, cmap=\"gray\")"
      ],
      "metadata": {
        "id": "y4OwJ_oWlB2G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}